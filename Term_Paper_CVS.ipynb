{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4528bbd",
   "metadata": {},
   "source": [
    "# Term Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346bf45",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b25dae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74325477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to compute and print dataset statistics\n",
    "def compute_statistics():\n",
    "    num_individuals = sce_df[\"userid\"].nunique() # Number of Unique userids (individuals)\n",
    "    num_observations = len(sce_df)               # Total number of observations\n",
    "    num_waves = sce_df[\"wid\"].nunique()          # Number of Unique survey waves\n",
    "    first_date = sce_df[\"date\"].min()            # Earliest survey date\n",
    "    last_date = sce_df[\"date\"].max() # Latest survey date\n",
    "\n",
    "    # Output the statistics\n",
    "    print(f\"Unique individuals: {num_individuals}\") \n",
    "    print(f\"Total observations: {num_observations}\")\n",
    "    print(f\"Unique survey waves: {num_waves}\")\n",
    "    print(f\"Date range: {first_date.date()} to {last_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17b74532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique individuals: 23369\n",
      "Total observations: 176101\n",
      "Unique survey waves: 139\n",
      "Date range: 2013-06-01 to 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "files=glob.glob(f'data/SCE-*-20*.csv')\n",
    "\n",
    "df_list=[]\n",
    "\n",
    "waves_number=0\n",
    "\n",
    "#Loop to read in and append files\n",
    "for file in files:\n",
    "    df=pd.read_csv(file,sep=\";\",parse_dates=['date'])\n",
    "    df_list.append(df)\n",
    "\n",
    "#Concatenate all dataframes into a single dataframe\n",
    "sce_df=pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "compute_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e6551",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32774343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeracy Score Distribution (%): numeracy_score\n",
      "0.0     0.111573\n",
      "1.0     0.659177\n",
      "2.0     2.001898\n",
      "3.0     5.215707\n",
      "4.0     9.579871\n",
      "5.0    16.597415\n",
      "6.0    27.303273\n",
      "7.0    38.531086\n",
      "Name: proportion, dtype: float64\n",
      "Unique individuals: 17701\n",
      "Total observations: 77976\n",
      "Unique survey waves: 117\n",
      "Date range: 2015-04-02 to 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "# Forward-fill numeracy variables for each individual\n",
    "numeracy_cols = [\n",
    "    'num_lit_q1_correct', 'num_lit_q2_correct', 'num_lit_q3_correct',\n",
    "    'num_lit_q5_correct', 'num_lit_q6_correct', 'num_lit_q8_correct', 'num_lit_q9_correct'\n",
    "]\n",
    "\n",
    "# Replace blank strings with NaN (if your CSV uses empty fields)\n",
    "sce_df[numeracy_cols] = sce_df[numeracy_cols].replace(\"\", pd.NA)\n",
    "\n",
    "\n",
    "# Group by userid, then forward-fill within each person\n",
    "sce_df[numeracy_cols] = sce_df.groupby('userid')[numeracy_cols].ffill()\n",
    "\n",
    "# Drop all rows that still have NaN\n",
    "numeracy_cols.extend(['female','educ','age','inflation','house_price_change','prob_stocks_up'])\n",
    "sce_df.dropna(subset=numeracy_cols,inplace=True)\n",
    "\n",
    "#Eliminate 0.1th percentile and 99.9th percentile of answers\n",
    "numeracy_cols = [\n",
    "    'num_lit_q1_correct', 'num_lit_q2_correct', 'num_lit_q3_correct',\n",
    "    'num_lit_q5_correct', 'num_lit_q6_correct', 'num_lit_q8_correct', 'num_lit_q9_correct'\n",
    "]\n",
    "lower_bounds=sce_df[numeracy_cols].quantile(0.001)\n",
    "upper_bounds=sce_df[numeracy_cols].quantile(0.999)\n",
    "for col in numeracy_cols:\n",
    "    sce_df=sce_df[(sce_df[col]>=lower_bounds[col]) & (sce_df[col]<=upper_bounds[col])]\n",
    "\n",
    "#Creating a column to determine whether the individual has a bachelor's degree or higher\n",
    "sce_df['college']=(sce_df['educ']>3).astype(int)\n",
    "\n",
    "#Compute the total number of correct numeracy responces\n",
    "sce_df['numeracy_score']=sce_df[numeracy_cols].sum(axis=1)\n",
    "\n",
    "#Compute the average numeracy score\n",
    "percentage=sce_df['numeracy_score'].value_counts(normalize=True)*100\n",
    "percentage.sort_index(inplace=True)\n",
    "print(f\"Numeracy Score Distribution (%): {percentage}\")\n",
    "\n",
    "#Creating a column to determine if the individual has a higher numeracy score than the median\n",
    "median_score = sce_df['numeracy_score'].median()\n",
    "sce_df['num_lit_high'] = (sce_df['numeracy_score'] > median_score).astype(int)\n",
    "\n",
    "#Calling the function to compute and print updated dataset statistics\n",
    "compute_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
